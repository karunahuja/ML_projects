{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stops=set(stopwords.words('english'))\n",
    "stops.update(list(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(             tweet_id airline_sentiment    airline airline_sentiment_gold  \\\n",
       " 0  567900433542488064          negative  Southwest                    NaN   \n",
       " 1  569989168903819264          positive  Southwest                    NaN   \n",
       " 2  568089179520954368          positive     United                    NaN   \n",
       " 3  568928195581513728          negative  Southwest                    NaN   \n",
       " 4  568594180014014464          negative     United                    NaN   \n",
       " \n",
       "             name negativereason_gold  retweet_count  \\\n",
       " 0  ColeyGirouard                 NaN              0   \n",
       " 1  WalterFaddoul                 NaN              0   \n",
       " 2      LocalKyle                 NaN              0   \n",
       " 3    amccarthy19                 NaN              0   \n",
       " 4        J_Okayy                 NaN              0   \n",
       " \n",
       "                                                 text tweet_coord  \\\n",
       " 0  @SouthwestAir I am scheduled for the morning, ...         NaN   \n",
       " 1  @SouthwestAir seeing your workers time in and ...         NaN   \n",
       " 2  @united Flew ORD to Miami and back and  had gr...         NaN   \n",
       " 3     @SouthwestAir @dultch97 that's horse radish üò§üê¥         NaN   \n",
       " 4  @united so our flight into ORD was delayed bec...         NaN   \n",
       " \n",
       "                tweet_created              tweet_location  \\\n",
       " 0  2015-02-17 20:16:29 -0800             Washington D.C.   \n",
       " 1  2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
       " 2  2015-02-18 08:46:29 -0800                    Illinois   \n",
       " 3  2015-02-20 16:20:26 -0800                         NaN   \n",
       " 4  2015-02-19 18:13:11 -0800                         NaN   \n",
       " \n",
       "                 user_timezone  \n",
       " 0      Atlantic Time (Canada)  \n",
       " 1  Central Time (US & Canada)  \n",
       " 2  Central Time (US & Canada)  \n",
       " 3      Atlantic Time (Canada)  \n",
       " 4  Eastern Time (US & Canada)  , tweet_id                  10980\n",
       " airline_sentiment         10980\n",
       " airline                   10980\n",
       " airline_sentiment_gold       31\n",
       " name                      10980\n",
       " negativereason_gold          24\n",
       " retweet_count             10980\n",
       " text                      10980\n",
       " tweet_coord                 776\n",
       " tweet_created             10980\n",
       " tweet_location             7430\n",
       " user_timezone              7403\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('0000000000002747_training_twitter_x_y_train.csv')\n",
    "test=pd.read_csv('0000000000002747_test_twitter_x_test.csv')\n",
    "train.head(),train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=np.array(train.text)\n",
    "target=np.array(train.airline_sentiment)\n",
    "testdata=np.array(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "countvec=CountVectorizer(max_features=1700,stop_words=stops,max_df=0.80)\n",
    "tdata=countvec.fit_transform(traindata)\n",
    "tstdata=countvec.transform(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10980x1700 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 90271 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3660x1700 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 29776 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tarun Ahuja\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9773224043715847"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=rfc()\n",
    "model.fit(tdata,target)\n",
    "model.score(tdata,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(tstdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('twt_sentiments.csv',pred,fmt='%s',delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
